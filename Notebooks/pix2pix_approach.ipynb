{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import lmdb\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "import kornia\n",
    "from skimage.color import lab2rgb\n",
    "\n",
    "\n",
    "from collections import OrderedDict\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "\n",
    "# pip install fastai==2.4\n",
    "from fastai.vision.learner import create_body\n",
    "from torchvision.models.resnet import resnet18\n",
    "from fastai.vision.models.unet import DynamicUnet\n",
    "\n",
    "\n",
    "from scipy import signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "TEMPO_LENGTH = 2 # (only used while trianing)\n",
    "SIZE = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lab_to_rgb(L, ab):\n",
    "    \"\"\"\n",
    "    Takes a batch of images\n",
    "    \"\"\"\n",
    "\n",
    "    L = (L + 1.) * 50.\n",
    "    ab = ab * 110.\n",
    "    Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().numpy()\n",
    "    rgb_imgs = []\n",
    "    for img in Lab:\n",
    "        img_rgb = lab2rgb(img)\n",
    "        rgb_imgs.append(img_rgb)\n",
    "    return np.stack(rgb_imgs, axis=0)\n",
    "\n",
    "class BaseDataset(Dataset):\n",
    "    def __init__(self, data_opt, **kwargs):\n",
    "        # dict to attr\n",
    "        for kw, args in data_opt.__dict__.items():\n",
    "            setattr(self, kw, args)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        pass\n",
    "\n",
    "   \n",
    "    @staticmethod\n",
    "    def init_lmdb(seq_dir):\n",
    "        env = lmdb.open(\n",
    "            seq_dir, readonly=True, lock=False, readahead=False, meminit=False)\n",
    "        return env\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_lmdb_key(key):\n",
    "        key_lst = key.split('_')\n",
    "        idx, size, frm = key_lst[:-2], key_lst[-2], int(key_lst[-1])\n",
    "        idx = '_'.join(idx)\n",
    "        size = tuple(map(int, size.split('x')))  # n_frm, h, w\n",
    "        return idx, size, frm\n",
    "\n",
    "    @staticmethod\n",
    "    def read_lmdb_frame(env, key, size):\n",
    "        with env.begin(write=False) as txn:\n",
    "            buf = txn.get(key.encode('ascii'))\n",
    "        frm = np.frombuffer(buf, dtype=np.uint8).reshape(*size)\n",
    "        return frm\n",
    "\n",
    "    def crop_sequence(self, **kwargs):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def augment_sequence(**kwargs):\n",
    "        pass\n",
    "\n",
    "\n",
    "class PairedLMDBDataset(BaseDataset):\n",
    "    \"\"\" LMDB dataset for paired data (for BI degradation)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_opt, **kwargs):\n",
    "        super(PairedLMDBDataset, self).__init__(data_opt, **kwargs)\n",
    "        \n",
    "        self.lr_seq_dir = data_opt.lr_seq_dir\n",
    "        self.data_type = data_opt.data_type\n",
    "        self.scale = data_opt.scale\n",
    "        self.tempo_extent = data_opt.tempo_extent\n",
    "        self.moving_first_frame = data_opt.moving_first_frame\n",
    "        self.moving_factor = data_opt.moving_factor\n",
    "        self.filter_file = data_opt.filter_file\n",
    "        \n",
    "        self.transform = torchvision.transforms.Compose([torchvision.transforms.Resize((256, 256))])\n",
    "\n",
    "        # load meta info\n",
    "        lr_meta = pickle.load(\n",
    "            open(osp.join(self.lr_seq_dir, 'meta_info.pkl'), 'rb'))\n",
    "        self.lr_keys = sorted(lr_meta['keys'])\n",
    "        \n",
    "        # register parameters\n",
    "        self.lr_env = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lr_keys)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        if self.lr_env is None:\n",
    "            self.lr_env = self.init_lmdb(self.lr_seq_dir)\n",
    "\n",
    "        # parse info\n",
    "        lr_key = self.lr_keys[item]\n",
    "        idx, (tot_frm, lr_h, lr_w), cur_frm = self.parse_lmdb_key(lr_key)\n",
    "\n",
    "        c = 3 if self.data_type.lower() == 'rgb' else 1\n",
    "        \n",
    "        # get frames\n",
    "        lr_frms = []\n",
    "        if self.moving_first_frame and (random.uniform(0, 1) > self.moving_factor):\n",
    "            # load the first gt&lr frame\n",
    "            lr_frm = self.read_lmdb_frame(\n",
    "                self.lr_env, lr_key, size=(lr_h, lr_w, c))\n",
    "            lr_frm = lr_frm.transpose(2, 0, 1)  # chw|rgb|uint8\n",
    "\n",
    "            # generate random moving parameters\n",
    "            offsets = np.floor(\n",
    "                np.random.uniform(-1.5, 1.5, size=(self.tempo_extent, 2)))\n",
    "            offsets = offsets.astype(np.int32)\n",
    "            pos = np.cumsum(offsets, axis=0)\n",
    "            min_pos = np.min(pos, axis=0)\n",
    "            topleft_pos = pos - min_pos\n",
    "            range_pos = np.max(pos, axis=0) - min_pos\n",
    "            c_h, c_w = lr_h - range_pos[0], lr_w - range_pos[1]\n",
    "\n",
    "            # generate frames\n",
    "            for i in range(self.tempo_extent):\n",
    "                lr_top, lr_left = topleft_pos[i]\n",
    "                lr_frms.append(lr_frm[\n",
    "                    :, lr_top: lr_top + c_h, lr_left: lr_left + c_w].copy())\n",
    "\n",
    "        else:\n",
    "            # read frames\n",
    "            for i in range(cur_frm, cur_frm + self.tempo_extent):\n",
    "                if i >= tot_frm:\n",
    "                    # reflect temporal paddding, e.g., (0,1,2) -> (0,1,2,1,0)\n",
    "                    lr_key = '{}_{}x{}x{}_{:04d}'.format(\n",
    "                        idx, tot_frm, lr_h, lr_w, 2 * tot_frm - i - 2)\n",
    "                else:\n",
    "                    lr_key = '{}_{}x{}x{}_{:04d}'.format(\n",
    "                        idx, tot_frm, lr_h, lr_w, i)\n",
    "\n",
    "                lr_frm = self.read_lmdb_frame(\n",
    "                    self.lr_env, lr_key, size=(lr_h, lr_w, c))\n",
    "                lr_frm = lr_frm.transpose(2, 0, 1)\n",
    "                lr_frms.append(lr_frm)\n",
    "\n",
    "        lr_frms = np.stack(lr_frms)\n",
    "        lr_tsr = torch.FloatTensor(np.ascontiguousarray(lr_frms)) / 255\n",
    "        lr_tsr = self.transform(lr_tsr)\n",
    "\n",
    "        lr_tsr = kornia.color.rgb_to_lab(lr_tsr)\n",
    "        L = lr_tsr[:, 0:1, :, :]\n",
    "        ab = lr_tsr[:, 1:, :, :]\n",
    "        \n",
    "        L = L/ 50. - 1. # Between -1 and 1\n",
    "        ab = ab / 110. # Between -1 and 1\n",
    "        \n",
    "        return {'L': L, 'ab': ab}\n",
    "\n",
    " \n",
    "    @staticmethod\n",
    "    def augment_sequence(gt_pats, lr_pats):\n",
    "        # flip\n",
    "        axis = random.randint(1, 3)\n",
    "        if axis > 1:\n",
    "            gt_pats = np.flip(gt_pats, axis)\n",
    "            lr_pats = np.flip(lr_pats, axis)\n",
    "\n",
    "        # rotate 90 degree\n",
    "        k = random.randint(0, 3)\n",
    "        gt_pats = np.rot90(gt_pats, k, (2, 3))\n",
    "        lr_pats = np.rot90(lr_pats, k, (2, 3))\n",
    "\n",
    "        return gt_pats, lr_pats\n",
    "    \n",
    "\n",
    "class DatasetConfig:\n",
    "    def __init__(self, \n",
    "                 lr_seq_dir,\n",
    "                 data_type='rgb',\n",
    "                 scale=1,\n",
    "                 tempo_extent=5,\n",
    "                 moving_first_frame=False,\n",
    "                 moving_factor=0.5,\n",
    "                 filter_file=None):\n",
    "        self.lr_seq_dir = lr_seq_dir\n",
    "        self.data_type = data_type\n",
    "        self.scale = scale\n",
    "        self.tempo_extent = tempo_extent\n",
    "        self.moving_first_frame = moving_first_frame\n",
    "        self.moving_factor = moving_factor\n",
    "        self.filter_file = filter_file\n",
    "\n",
    "data_opt = DatasetConfig(\n",
    "    lr_seq_dir='/media/moose/Moose/Dataset/AMD/',\n",
    "    data_type='rgb',\n",
    "    scale=1,\n",
    "    tempo_extent=TEMPO_LENGTH,\n",
    "    moving_first_frame=False,\n",
    "    moving_factor=0.5,\n",
    "    filter_file=None\n",
    ")\n",
    "\n",
    "ds = PairedLMDBDataset(data_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(ds, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANLoss(nn.Module):\n",
    "    def __init__(self, gan_mode='vanilla', real_label=1.0, fake_label=0.0):\n",
    "        super().__init__()\n",
    "        self.register_buffer('real_label', torch.tensor(real_label))\n",
    "        self.register_buffer('fake_label', torch.tensor(fake_label))\n",
    "        if gan_mode == 'vanilla':\n",
    "            self.loss = nn.BCEWithLogitsLoss()\n",
    "        elif gan_mode == 'lsgan':\n",
    "            self.loss = nn.MSELoss()\n",
    "\n",
    "    def get_labels(self, preds, target_is_real):\n",
    "        if target_is_real:\n",
    "            labels = self.real_label\n",
    "        else:\n",
    "            labels = self.fake_label\n",
    "        return labels.expand_as(preds)\n",
    "\n",
    "    def __call__(self, preds, target_is_real):\n",
    "        labels = self.get_labels(preds, target_is_real)\n",
    "        loss = self.loss(preds, labels)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(net, init='norm', gain=0.02):\n",
    "\n",
    "    def init_func(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if hasattr(m, 'weight') and 'Conv' in classname:\n",
    "            if init == 'norm':\n",
    "                nn.init.normal_(m.weight.data, mean=0.0, std=gain)\n",
    "            elif init == 'xavier':\n",
    "                nn.init.xavier_normal_(m.weight.data, gain=gain)\n",
    "            elif init == 'kaiming':\n",
    "                nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                nn.init.constant_(m.bias.data, 0.0)\n",
    "        elif 'BatchNorm2d' in classname:\n",
    "            nn.init.normal_(m.weight.data, 1., gain)\n",
    "            nn.init.constant_(m.bias.data, 0.)\n",
    "\n",
    "    net.apply(init_func)\n",
    "    print(f\"model initialized with {init} initialization\")\n",
    "    return net\n",
    "\n",
    "def init_model(model, device):\n",
    "    model = model.to(device)\n",
    "    model = init_weights(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchDiscriminator(nn.Module):\n",
    "    def __init__(self, input_c, num_filters=64, n_down=3):\n",
    "        super().__init__()\n",
    "        model = [self.get_layers(input_c, num_filters, norm=False)]\n",
    "        model += [self.get_layers(num_filters * 2 ** i, num_filters * 2 ** (i + 1), s=1 if i == (n_down-1) else 2)\n",
    "                          for i in range(n_down)] # the 'if' statement is taking care of not using\n",
    "                                                  # stride of 2 for the last block in this loop\n",
    "        model += [self.get_layers(num_filters * 2 ** n_down, 1, s=1, norm=False, act=False)] # Make sure to not use normalization or\n",
    "                                                                                             # activation for the last layer of the model\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def get_layers(self, ni, nf, k=4, s=2, p=1, norm=True, act=True): # when needing to make some repeatitive blocks of layers,\n",
    "        layers = [nn.Conv2d(ni, nf, k, s, p, bias=not norm)]          # it's always helpful to make a separate method for that purpose\n",
    "        if norm: layers += [nn.BatchNorm2d(nf)]\n",
    "        if act: layers += [nn.LeakyReLU(0.2, True)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_res_unet(n_input=1, n_output=2, size=SIZE):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    body = create_body(resnet18(), pretrained=True, n_in=n_input, cut=-2)\n",
    "    net_G = DynamicUnet(body, n_output, (size, size)).to(device)\n",
    "    return net_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NDIM_LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self,size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.percent_ltr_input=nn.Parameter(torch.empty(size).normal_(mean=0.0,std=1.0),requires_grad=True)\n",
    "        self.percent_ltr_stm_wt=nn.Parameter(torch.empty(size).normal_(mean=0.0,std=1.0),requires_grad=True)\n",
    "        self.b1=nn.Parameter(torch.tensor(0.),requires_grad=False)\n",
    "\n",
    "        self.percent_potential_ltm_stm_wt=nn.Parameter(torch.empty(size).normal_(mean=0.0,std=1.0),requires_grad=True)\n",
    "        self.percent_potential_ltm_input=nn.Parameter(torch.empty(size).normal_(mean=0.0,std=1.0),requires_grad=True)\n",
    "        self.b2=nn.Parameter(torch.tensor(0.),requires_grad=False)\n",
    "        \n",
    "        self.potential_ltm_stm_wt=nn.Parameter(torch.empty(size).normal_(mean=0.0,std=1.0),requires_grad=True)\n",
    "        self.potential_ltm_input=nn.Parameter(torch.empty(size).normal_(mean=0.0,std=1.0),requires_grad=True)\n",
    "        self.b3=nn.Parameter(torch.tensor(0.),requires_grad=False)\n",
    "        \n",
    "        self.output_stm_contri_stm_wt=nn.Parameter(torch.empty(size).normal_(mean=0.0,std=1.0),requires_grad=True)\n",
    "        self.output_stm_contri_input=nn.Parameter(torch.empty(size).normal_(mean=0.0,std=1.0),requires_grad=True)\n",
    "        self.b4=nn.Parameter(torch.tensor(0.),requires_grad=False)\n",
    "\n",
    "    def lstm_unit(self,input_value,long_memory,short_memory):\n",
    "        \n",
    "        long_remember_percent=torch.sigmoid((input_value*self.percent_ltr_input)+\n",
    "                                            (self.percent_ltr_stm_wt*short_memory)+\n",
    "                                            self.b1)\n",
    "        \n",
    "        potential_remember_percent=torch.sigmoid((input_value*self.percent_potential_ltm_input)+\n",
    "                                                 (short_memory*self.percent_potential_ltm_stm_wt)+\n",
    "                                                  self.b2)\n",
    "\n",
    "        potential_memory = torch.tanh((short_memory * self.potential_ltm_stm_wt) + \n",
    "                                  (input_value * self.potential_ltm_input) + \n",
    "                                  self.b3)\n",
    "        \n",
    "        updated_long_memory = ((long_memory * long_remember_percent) + \n",
    "               (potential_remember_percent * potential_memory))\n",
    "\n",
    "        output_percent = torch.sigmoid((short_memory * self.output_stm_contri_stm_wt) + \n",
    "                                       (input_value * self.output_stm_contri_input) + \n",
    "                                       self.b4)         \n",
    "        \n",
    "        updated_short_memory = torch.tanh(updated_long_memory) * output_percent\n",
    "        \n",
    "        \n",
    "        updated_long_memory = torch.tanh(updated_long_memory)\n",
    "        updated_short_memory = torch.tanh(updated_short_memory)\n",
    "        \n",
    "        return([updated_long_memory, updated_short_memory])\n",
    "\n",
    "    def forward(self, input, long_memory=0, short_memory=0): \n",
    "        \n",
    "        return self.lstm_unit(input,long_memory,short_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.unet = build_res_unet(n_input=3, n_output=2, size=SIZE)\n",
    "        self.lstm = NDIM_LSTM((2,SIZE,SIZE)).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "    \n",
    "    def forward(self, L, prev_ab = None):\n",
    "        if(prev_ab is None):\n",
    "            #print(torch.squeeze(L,dim=1).shape)\n",
    "            L = torch.squeeze(L,dim=1)\n",
    "            n,c,h,w = L.shape\n",
    "            prev_ab = torch.zeros(n, 2, h, w, device='cuda' if torch.cuda.is_available() else 'cpu', dtype=torch.float32)\n",
    "        x = torch.concat([L, prev_ab], dim=1)\n",
    "        pred_ab = self.unet(x)\n",
    "        stm, ltm = self.lstm(pred_ab)\n",
    "        return {'pred_ab': pred_ab, 'stm': stm, 'ltm': ltm}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorNetGAN(nn.Module):\n",
    "    def __init__(self, net_G=None, lr_G=2e-4, lr_D=2e-4,\n",
    "                 beta1=0.5, beta2=0.999, lambda_L1=100.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.lambda_L1 = lambda_L1\n",
    "\n",
    "        if net_G is None:\n",
    "            self.net_G = ColorNet().to(self.device)\n",
    "        else:\n",
    "            self.net_G = net_G.to(self.device)\n",
    "        self.net_D = init_model(PatchDiscriminator(input_c=3, n_down=3, num_filters=64), self.device)\n",
    "        self.GANcriterion = GANLoss(gan_mode='vanilla').to(self.device)\n",
    "        self.L1criterion = nn.L1Loss()\n",
    "        self.opt_G = torch.optim.Adam(self.net_G.parameters(), lr=lr_G, betas=(beta1, beta2))\n",
    "        self.opt_D = torch.optim.Adam(self.net_D.parameters(), lr=lr_D, betas=(beta1, beta2))\n",
    "\n",
    "    def set_requires_grad(self, model, requires_grad=True):\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = requires_grad\n",
    "\n",
    "    def setup_input(self, data):\n",
    "        self.L = data['L'].to(self.device)\n",
    "        self.ab = data['ab'].to(self.device)\n",
    "\n",
    "    def forward(self):\n",
    "        n, self.t, c, lr_h, lr_w = self.L.size()\n",
    "        ab_data = []\n",
    "        \n",
    "        preds = self.net_G(torch.unsqueeze(self.L[:, 0, ...],dim=1))\n",
    "        \n",
    "        \n",
    "        ab_data.append(preds['stm'])\n",
    "\n",
    "        # compute the remaining hr data\n",
    "        for i in range(1, self.t):\n",
    "            ab_curr = self.net_G(self.L[:, i, ...], ab_data[i-1])\n",
    "            ab_data.append(ab_curr['stm'])\n",
    "\n",
    "        self.ab_data = torch.stack(ab_data, dim=1)\n",
    "\n",
    "    def backward_D(self):\n",
    "        self.loss_D_fake = 0\n",
    "        self.loss_D_real = 0\n",
    "\n",
    "        for i in range(self.t):\n",
    "            fake_image = torch.cat([self.L[:, i, ...], self.ab_data[:, i, ...]], dim=1)\n",
    "            fake_preds = self.net_D(fake_image.detach())\n",
    "            self.loss_D_fake += self.GANcriterion(fake_preds, False)\n",
    "\n",
    "            real_image = torch.cat([self.L[:, i, ...], self.ab[:, i, ...]], dim=1)\n",
    "            real_preds = self.net_D(real_image)\n",
    "            self.loss_D_real += self.GANcriterion(real_preds, True)\n",
    "\n",
    "        self.loss_D_fake /= self.t\n",
    "        self.loss_D_real /= self.t\n",
    "        self.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5\n",
    "        self.loss_D.backward()\n",
    "\n",
    "    def backward_G(self):\n",
    "        self.loss_G_GAN = 0\n",
    "        self.loss_G_L1 = 0\n",
    "\n",
    "        for i in range(self.t):\n",
    "            fake_image = torch.cat([self.L[:, i, ...], self.ab_data[:, i, ...]], dim=1)\n",
    "            fake_preds = self.net_D(fake_image)\n",
    "            self.loss_G_GAN += self.GANcriterion(fake_preds, True)\n",
    "            self.loss_G_L1 += self.L1criterion(self.ab_data[:, i, ...], self.ab[:, i, ...]) * self.lambda_L1\n",
    "\n",
    "        self.loss_G_GAN /= self.t\n",
    "        self.loss_G_L1 /= self.t\n",
    "        self.loss_G = self.loss_G_GAN + self.loss_G_L1\n",
    "        self.loss_G.backward()\n",
    "\n",
    "    def optimize(self):\n",
    "        self.forward()\n",
    "        self.net_D.train()\n",
    "        self.set_requires_grad(self.net_D, True)\n",
    "        self.opt_D.zero_grad()\n",
    "        self.backward_D()\n",
    "        self.opt_D.step()\n",
    "\n",
    "        self.net_G.train()\n",
    "        self.set_requires_grad(self.net_D, False)\n",
    "        self.opt_G.zero_grad()\n",
    "        self.backward_G()\n",
    "        self.opt_G.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model initialized with norm initialization\n"
     ]
    }
   ],
   "source": [
    "model=ColorNetGAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moose/miniconda3/envs/torch/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data1=next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.setup_input(data1)\n",
    "model.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
